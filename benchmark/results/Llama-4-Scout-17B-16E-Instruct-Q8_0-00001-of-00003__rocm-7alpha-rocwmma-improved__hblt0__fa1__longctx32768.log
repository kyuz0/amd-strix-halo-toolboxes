ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 ROCm devices:
  Device 0: Radeon 8060S Graphics, gfx1151 (0x1151), VMM: no, Wave Size: 32
| model                          |       size |     params | backend    | ngl | n_ubatch | fa | mmap |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | -------: | -: | ---: | --------------: | -------------------: |
| llama4 17Bx16E (Scout) Q8_0    | 106.65 GiB |   107.77 B | ROCm       |  99 |     2048 |  1 |    0 | pp2048 @ d32768 |        153.04 ± 0.00 |
/opt/llama.cpp/ggml/src/ggml-cuda/ggml-cuda.cu:89: ROCm error
/usr/local/lib64/libggml-base.so.0(+0x3565) [0x7f0845525565]
/usr/local/lib64/libggml-base.so.0(ggml_print_backtrace+0x1eb) [0x7f084552592b]
/usr/local/lib64/libggml-base.so.0(ggml_abort+0x11f) [0x7f0845525aaf]
/usr/local/lib64/libggml-hip.so.0(+0x31feeb2) [0x7f08487deeb2]
/usr/local/lib64/libggml-hip.so.0(+0x3204034) [0x7f08487e4034]
/usr/local/lib64/libggml-base.so.0(ggml_backend_sched_synchronize+0x2e) [0x7f084553c8ce]
/usr/local/lib64/libllama.so.0(_ZN13llama_context11synchronizeEv+0x10) [0x7f0848e9a950]
/usr/local/bin/llama-bench() [0x408242]
/lib64/libc.so.6(+0x35b5) [0x7f0844ebb5b5]
/lib64/libc.so.6(__libc_start_main+0x88) [0x7f0844ebb668]
/usr/local/bin/llama-bench() [0x409255]
✖ ! [rocm-7alpha-rocwmma-improved] Llama-4-Scout-17B-16E-Instruct-Q8_0-00001-of-00003__hblt0__fa1 __longctx32768 failed (exit 0)

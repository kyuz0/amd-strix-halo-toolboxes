ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = Radeon 8060S Graphics (RADV GFX1151) (radv) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 65536 | int dot: 1 | matrix cores: KHR_coopmat
| model                          |       size |     params | backend    | ngl | fa | mmap |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | -: | ---: | --------------: | -------------------: |
/opt/llama.cpp/ggml/src/ggml-rpc/ggml-rpc.cpp:724: Remote RPC server crashed or returned malformed response
/lib64/libggml-base.so.0(+0x35a5) [0x7fe6965fe5a5]
/lib64/libggml-base.so.0(ggml_print_backtrace+0x1eb) [0x7fe6965fe96b]
/lib64/libggml-base.so.0(ggml_abort+0x11f) [0x7fe6965feaef]
/lib64/libggml-rpc.so.0(+0x5b4a) [0x7fe699c23b4a]
/lib64/libggml-base.so.0(+0x171b2) [0x7fe6966121b2]
/lib64/libggml-base.so.0(+0x1749f) [0x7fe69661249f]
/lib64/libggml-base.so.0(ggml_backend_alloc_ctx_tensors_from_buft+0x19) [0x7fe696613509]
/lib64/libllama.so.0(_ZN11llama_model12load_tensorsER18llama_model_loader+0x3c61) [0x7fe699e733c1]
/lib64/libllama.so.0(+0x25568) [0x7fe699dc9568]
/lib64/libllama.so.0(llama_model_load_from_file+0xac) [0x7fe699dca3cc]
/usr/sbin/llama-bench() [0x4077b5]
/lib64/libc.so.6(+0x35b5) [0x7fe695f945b5]
/lib64/libc.so.6(__libc_start_main+0x88) [0x7fe695f94668]
/usr/sbin/llama-bench() [0x409cf5]

ggml_vulkan: Found 1 Vulkan devices:
ggml_vulkan: 0 = Radeon 8060S Graphics (AMD open-source driver) | uma: 1 | fp16: 1 | bf16: 0 | warp size: 64 | shared memory: 32768 | int dot: 1 | matrix cores: KHR_coopmat
| model                          |       size |     params | backend    | ngl | fa |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | --: | -: | --------------: | -------------------: |
/opt/llama.cpp/ggml/src/ggml-rpc/ggml-rpc.cpp:724: Remote RPC server crashed or returned malformed response
/lib64/libggml-base.so.0(+0x35a5) [0x7f14eecbd5a5]
/lib64/libggml-base.so.0(ggml_print_backtrace+0x1eb) [0x7f14eecbd96b]
/lib64/libggml-base.so.0(ggml_abort+0x11f) [0x7f14eecbdaef]
/lib64/libggml-rpc.so.0(+0x5b4a) [0x7f14f2311b4a]
/lib64/libggml-base.so.0(+0x174f2) [0x7f14eecd14f2]
/lib64/libggml-base.so.0(+0x177df) [0x7f14eecd17df]
/lib64/libggml-base.so.0(ggml_backend_alloc_ctx_tensors_from_buft+0x19) [0x7f14eecd2849]
/lib64/libllama.so.0(_ZN11llama_model12load_tensorsER18llama_model_loader+0x3c41) [0x7f14f257dbe1]
/lib64/libllama.so.0(+0x279e8) [0x7f14f24c79e8]
/lib64/libllama.so.0(llama_model_load_from_file+0xac) [0x7f14f24c884c]
/usr/sbin/llama-bench() [0x407fbd]
/lib64/libc.so.6(+0x35b5) [0x7f14ee1055b5]
/lib64/libc.so.6(__libc_start_main+0x88) [0x7f14ee105668]
/usr/sbin/llama-bench() [0x40a7b5]
